{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-27T06:49:12.375581Z",
     "start_time": "2024-12-27T06:49:12.365947Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torchvision.transforms.functional\n",
    "from matplotlib import pyplot as plt\n",
    "import torch\n",
    "import numpy as np\n",
    "from functools import partial\n",
    "import torchvision.transforms as transforms\n",
    "import os\n",
    "from dipy.io import read_bvals_bvecs\n",
    "from dipy.io.image import load_nifti\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "import torchvision.transforms as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f8975a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from dipy.io.image import load_nifti\n",
    "from nibabel import Nifti1Image\n",
    "from dipy.io import read_bvals_bvecs\n",
    "import shutil\n",
    "root = '/mnt/HCP_3T_251/'\n",
    "log_path = os.path.join(root, 'problematic_subjects.log')\n",
    "\n",
    "# Ensure log file is empty at the start\n",
    "with open(log_path, 'w') as log_file:\n",
    "    log_file.write('')\n",
    "\n",
    "files = sorted(os.listdir(root))\n",
    "\n",
    "for file in files:\n",
    "    file_str = str(file)\n",
    "    file_name = file_str.split(\"_\")[0]\n",
    "    print(f\"subj {file_name} starts\")\n",
    "    data_path = os.path.join(root, file_name, 'T1w', 'Diffusion', 'data.nii.gz')\n",
    "    bval_path = os.path.join(root, file_name, 'T1w', 'Diffusion', 'bvals')\n",
    "    bvec_path = os.path.join(root, file_name, 'T1w', 'Diffusion', 'bvecs')\n",
    "    mask_path = os.path.join(root, file_name, 'T1w', 'Diffusion', 'nodif_brain_mask.nii.gz')\n",
    "    save_path_90 = os.path.join(root, file_name, 'diffusion_90_directions')\n",
    "    save_path_180 = os.path.join(root, file_name, 'diffusion_180_directions')\n",
    "    save_path_270 = os.path.join(root, file_name, 'diffusion_270_directions')\n",
    "    os.makedirs(save_path_90, exist_ok=True)\n",
    "    os.makedirs(save_path_180, exist_ok=True)\n",
    "    os.makedirs(save_path_270, exist_ok=True)\n",
    "\n",
    "\n",
    "    try:\n",
    "        data, affine = load_nifti(data_path)\n",
    "        bvals, bvecs = read_bvals_bvecs(bval_path, bvec_path)\n",
    "\n",
    "        if data.shape[-1] != 288:\n",
    "            with open(log_path, 'a') as log_file:\n",
    "                log_file.write(f\"{file_name} has incorrect data shape: {data.shape}\\n\")\n",
    "            continue\n",
    "\n",
    "        b0, b1, b2, b3 = [], [], [], []\n",
    "        for i in range(288):\n",
    "            b = bvals[i]\n",
    "            if abs(b - 0) == min(abs(b - 0), abs(b - 1000), abs(b - 2000), abs(b - 3000)):\n",
    "                b0.append(i)\n",
    "            elif abs(b - 1000) == min(abs(b - 0), abs(b - 1000), abs(b - 2000), abs(b - 3000)):\n",
    "                b1.append(i)\n",
    "            elif abs(b - 2000) == min(abs(b - 0), abs(b - 1000), abs(b - 2000), abs(b - 3000)):\n",
    "                b2.append(i)\n",
    "            else:\n",
    "                b3.append(i)\n",
    "\n",
    "        b0_data = data[:, :, :, b0]\n",
    "        \n",
    "        b1_data = data[:, :, :, b1]\n",
    "        b1_bvals = bvals[b1]\n",
    "        b1_bvecs = bvecs[b1, :]\n",
    "                \n",
    "        # b2_data = data[:, :, :, b2]\n",
    "        # b2_bvals = bvals[b2]\n",
    "        # b2_bvecs = bvecs[b2, :]\n",
    "        \n",
    "        # b3_data = data[:, :, :, b3]\n",
    "        # b3_bvals = bvals[b3]\n",
    "        # b3_bvecs = bvecs[b3, :]\n",
    "\n",
    "        # save shell data nii file\n",
    "        print(f\"subj {file_name} is being processed\")\n",
    "        GT_mask, _ = load_nifti(mask_path)\n",
    "        average_b0 = np.mean(b0_data, axis=3)\n",
    "        b0 = np.expand_dims(average_b0, 3)\n",
    "        data_gt = b1_data / (b0 + 1e-5)\n",
    "        data_gt = np.nan_to_num(data_gt, copy=True, nan=0, posinf=0, neginf=0)\n",
    "        data_gt = np.clip(data_gt, 0, 1)\n",
    "        data_gt *= np.expand_dims(GT_mask, axis=-1)\n",
    "        print(f\"subj {file_name} is saving\")\n",
    "        new_image = Nifti1Image(data_gt, np.eye(4))\n",
    "        Nifti1Image(data_gt, affine).to_filename(os.path.join(save_path_90, f'{file_name}_90.nii.gz'))\n",
    "        Nifti1Image(GT_mask, affine).to_filename(os.path.join(save_path_90, f'{file_name}_brain_mask.nii.gz'))\n",
    "\n",
    "        np.savetxt(os.path.join(save_path_90, f'{file_name}_bvecs_90.txt'), b1_bvecs, delimiter=' ')\n",
    "        np.savetxt(os.path.join(save_path_90, f'{file_name}_bvals_90.txt'), b1_bvals, delimiter=' ')\n",
    "        # np.savetxt(os.path.join(save_path_180, f'{file_name}_bvecs_180.txt'), b2_bvecs, delimiter=' ')\n",
    "        # np.savetxt(os.path.join(save_path_180, f'{file_name}_bvals_180.txt'), b2_bvals, delimiter=' ')\n",
    "        # np.savetxt(os.path.join(save_path_270, f'{file_name}_bvecs_270.txt'), b3_bvecs, delimiter=' ')\n",
    "        # np.savetxt(os.path.join(save_path_270, f'{file_name}_bvals_270.txt'), b3_bvals, delimiter=' ')\n",
    "\n",
    "        # print(f\"subj {file_name} is done\")\n",
    "\n",
    "    except Exception as e:\n",
    "        with open(log_path, 'a') as log_file:\n",
    "            log_file.write(f\"{file_name} processing failed: {str(e)}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f1c49e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# —————————————————————————————————————————————————————————————————————————————————————————————————————————————\n",
    "# |                              Generate 90 directions from 288 directions P2S denoised subjects             |     \n",
    "# —————————————————————————————————————————————————————————————————————————————————————————————————————————————\n",
    "root = '/mnt/disk4/hcp_fa_ad/hcp-78/'\n",
    "save_path = '/mnt/disk1/munan/hcp_single/'\n",
    "noddi_path = '/mnt/disk4/hcp_fa_ad/NODDI_LABELS/'\n",
    "normalise = True\n",
    "os.makedirs(save_path, exist_ok=True)\n",
    "# sort files\n",
    "files = sorted(os.listdir(root))\n",
    "# index_1 = [7, 37, 39, 68, 69, 81]\n",
    "# index_1_random = [4, 7, 17, 37, 45, 52, 58 ,68, 69, 81]\n",
    "index_1 = [4, 7, 17, 37, 45, 52]\n",
    "index_1_30 =[1, 4, 7, 10, 15, 17, 20, 25, 27, 30, 37, 39, 43, 45, 48, 50, 52, 54, 56, 58, 60, 68, 69, 72, 75, 78, 81, 83,\n",
    "         85, 88]\n",
    "index_2 = [1, 4, 25, 30, 72, 76]\n",
    "index_3 = [26, 45, 58, 71, 73, 80]\n",
    "for file in files[:1]:\n",
    "    \n",
    "    file_str = str(file)\n",
    "    file_name = file_str.split(\"_\")[0]\n",
    "    print(file,file_name)\n",
    "    os.makedirs(os.path.join(save_path,file_name), exist_ok=True)\n",
    "\n",
    "\n",
    "    # os.makedirs((osp.join(save_path,file_name)), exist_ok=True)\n",
    "    data_path = root  + file + '/' + file_name + '/T1w/Diffusion/data.nii.gz'\n",
    "    bval_path = root  + file + '/' + file_name + '/T1w/Diffusion/bvals'\n",
    "    bvec_path = root  + file + '/' + file_name + '/T1w/Diffusion/bvecs'\n",
    "    # fa_path = root + file + '/' + file_name + '/T1w/Diffusion/fa.nii.gz'\n",
    "    # ad_path = root + file + '/' + file_name + '/T1w/Diffusion/ad.nii.gz'\n",
    "    # md_path = root + file + '/' + file_name + '/T1w/Diffusion/md.nii.gz'\n",
    "    # od_path = noddi_path + file_name + '/FIT_OD.nii.gz'\n",
    "    # ic_path = noddi_path + file_name + '/FIT_ICVF.nii.gz'\n",
    "    # iso_path = noddi_path + file_name + '/FIT_ISOVF.nii.gz'\n",
    "    mask_path = root  + file + '/' + file_name + '/T1w/Diffusion/nodif_brain_mask.nii.gz'\n",
    "    \n",
    "    \n",
    "    rcnn_result_path = \"/home/munan/VDT/rcnn/100206_inferred_90.nii.gz\"\n",
    "    rcnn,_=load_nifti(rcnn_result_path) \n",
    "    # dmri_out = f\"/mnt/disk1/munan/hcp_single/100206/100206_inferred_sh.nii.gz\"\n",
    "    # sh,_ = load_nifti(dmri_out)\n",
    "    \n",
    "    # data.shape (145, 174, 145, 288)\n",
    "    data, affine = load_nifti(data_path)\n",
    "    mask,_ = load_nifti(mask_path)\n",
    "\n",
    "    mask_new = nib.Nifti1Image(mask, np.eye(4))\n",
    "    nib.save(mask_new,osp.join(save_path,file_name,f'{file_name}_brain_mask.nii.gz'))\n",
    "    print(\"mask saved\")\n",
    "    \n",
    "    # bvals = 0, 1000, 2000, 3000; bvecs.shape (288, 3)\n",
    "    bvals, bvecs = read_bvals_bvecs(bval_path, bvec_path)\n",
    "    # if data.shape[-1] != 288:\n",
    "    #     raise \"dwi original data's shape is not right\"\n",
    "    b0 = []\n",
    "    b1 = []\n",
    "    b2 = []\n",
    "    b3 = []\n",
    "    i = 0\n",
    "\n",
    "    for i in range(288):\n",
    "        b = bvals[i]\n",
    "        if abs(b - 0) == min(abs(b - 0), abs(b - 1000), abs(b - 2000), abs(b - 3000)):\n",
    "            b0.append(i)\n",
    "        elif abs(b - 1000) == min(abs(b - 0), abs(b - 1000), abs(b - 2000), abs(b - 3000)):\n",
    "            b1.append(i)\n",
    "        elif abs(b - 2000) == min(abs(b - 0), abs(b - 1000), abs(b - 2000), abs(b - 3000)):\n",
    "            b2.append(i)\n",
    "        else:\n",
    "            b3.append(i)\n",
    "    b1_data = data[:, :, :, b1]\n",
    "    print(\"data_b1: \",b1_data.min(), b1_data.max())\n",
    "    b1_bvals = bvals[b1] \n",
    "    b1_bvecs = bvecs[b1, :]\n",
    "    GT_mask, _ = load_nifti(mask_path)\n",
    "    print(\"生成mask\")\n",
    "    if normalise:\n",
    "        b0_data = data[:, :, :, b0] #shape [slice,h,w,dim]\n",
    "        b0_bvals = bvals[b0]\n",
    "        b0_bvecs = bvecs[b0, :]\n",
    "        # print(\"GT mask shape:\\t\", GT_mask.shape)  \n",
    "        average_b0 = np.mean(b0_data, axis=3) #shape [slice,h,w]\n",
    "        b0 = np.expand_dims(average_b0, 3) # (145, 174, 145, 1)\n",
    "        print(\"data_b0: \",b0.min(), b0.max())\n",
    "        print(\"b0 average\")          \n",
    "        print(\"正则化begin\")\n",
    "        data_gt = b1_data / (b0+1e-5)#除b0正则化\n",
    "        print(\"data_gt: \",data_gt.min(), data_gt.max())\n",
    "        data_gt = np.nan_to_num(data_gt, copy=True, nan=0, posinf=0, neginf=0)\n",
    "        data_gt = np.clip(data_gt, 0, 1)\n",
    "        data_gt = data_gt * np.expand_dims(GT_mask, axis=-1)\n",
    "        b1_data = data_gt\n",
    "        print(\"正则化done\")\n",
    "\n",
    "        rcnn = rcnn/(b0+1e-5)\n",
    "        rcnn = np.nan_to_num(rcnn, copy=True, nan=0, posinf=0, neginf=0)\n",
    "        rcnn = np.clip(rcnn, 0, 1)\n",
    "        rcnn = rcnn*np.expand_dims(GT_mask, axis=-1)\n",
    "        new_image_norm = nib.Nifti1Image(rcnn, np.eye(4)) \n",
    "        nib.save(new_image_norm, osp.join(\"/home/munan/VDT/rcnn\",f'100206_inferred_rcnn_2nd_norm.nii.gz'))\n",
    "        # \n",
    "        # sh = sh/(b0+1e-5)\n",
    "        # sh = np.nan_to_num(sh, copy=True, nan=0, posinf=0, neginf=0)\n",
    "        # sh = np.clip(sh, 0, 1)\n",
    "        # sh = sh*np.expand_dims(GT_mask, axis=-1)\n",
    "        # new_image_norm_sh = nib.Nifti1Image(sh, np.eye(4)) \n",
    "        # nib.save(new_image_norm_sh, osp.join(\"/mnt/disk1/munan/hcp_single/100206/\",f'100206_inferred_sh_norm.nii.gz'))\n",
    "    \n",
    "    else:\n",
    "        b1_data = b1_data * np.expand_dims(GT_mask, axis=-1)\n",
    "    print(\"data_b1: \",b1_data.min(), b1_data.max())\n",
    "    \n",
    "    # # print(b1_data.shape)\n",
    "    # new_image = nib.Nifti1Image(b1_data, np.eye(4)) \n",
    "    # nib.save(new_image, osp.join(save_path,file_name,f'{file_name}_90.nii.gz'))\n",
    "    # np.savetxt(osp.join(save_path,file_name,f'{file_name}_bvecs_90.txt'), b1_bvecs, delimiter=' ')\n",
    "    # np.savetxt(osp.join(save_path,file_name,f'{file_name}_bvals_90.txt'), b1_bvals, delimiter=' ')\n",
    "\n",
    "    # b1_data_selected = b1_data[:, :, :, index_1]\n",
    "    # b1_bvals_selected = b1_bvals[index_1]\n",
    "    # b1_bvecs_selected = b1_bvecs[index_1, :]\n",
    "    # # print(b1_data_selected.shape)\n",
    "    # new_image_6 = nib.Nifti1Image(b1_data_selected, np.eye(4)) \n",
    "    # nib.save(new_image_6, osp.join(save_path,file_name,f'{file_name}_06_2nd.nii.gz'))\n",
    "    # np.savetxt(osp.join(save_path,file_name,f'{file_name}_bvecs_06_2nd.txt'), b1_bvecs_selected, delimiter=' ')\n",
    "    # np.savetxt(osp.join(save_path,file_name,f'{file_name}_bvals_06_2nd.txt'), b1_bvals_selected, delimiter=' ')\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2720d8016cc98c90",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-27T07:39:34.314717Z",
     "start_time": "2024-12-27T07:19:21.161350Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "处理完成: 108525\n",
      "处理完成: 124826\n",
      "处理完成: 104012\n",
      "处理完成: 102715\n",
      "处理完成: 107018\n",
      "处理完成: 112516\n",
      "处理完成: 124220\n",
      "处理完成: 125222\n",
      "处理完成: 110411\n",
      "处理完成: 111211\n",
      "处理完成: 103818\n",
      "处理完成: 110613\n",
      "处理完成: 101107\n",
      "处理完成: 108323\n",
      "处理完成: 122317\n",
      "处理完成: 123420\n",
      "处理完成: 102311\n",
      "处理完成: 120717\n",
      "处理完成: 101410\n",
      "处理完成: 101309\n",
      "处理完成: 109830\n",
      "处理完成: 112314\n",
      "处理完成: 111009\n",
      "处理完成: 103212\n",
      "处理完成: 106016\n",
      "处理完成: 122620\n",
      "处理完成: 122418\n",
      "处理完成: 103010\n",
      "处理完成: 108121\n",
      "处理完成: 121618\n",
      "处理完成: 122822\n",
      "处理完成: 105620\n",
      "处理完成: 107321\n",
      "处理完成: 100408\n",
      "处理完成: 100307\n",
      "处理完成: 107725\n",
      "处理完成: 110007\n",
      "处理完成: 121416\n",
      "处理完成: 111413\n",
      "处理完成: 105014\n",
      "处理完成: 124624\n",
      "处理完成: 121921\n",
      "处理完成: 123723\n",
      "处理完成: 123925\n",
      "处理完成: 101006\n",
      "处理完成: 101915\n",
      "处理完成: 108828\n",
      "处理完成: 121719\n",
      "处理完成: 106319\n",
      "处理完成: 100206\n",
      "处理完成: 105923\n",
      "处理完成: 102614\n",
      "处理完成: 111716\n",
      "处理完成: 103515\n",
      "处理完成: 123521\n",
      "处理完成: 106521\n",
      "处理完成: 123117\n",
      "处理完成: 105216\n",
      "处理完成: 124422\n",
      "处理完成: 104416\n",
      "处理完成: 112112\n",
      "处理完成: 102513\n",
      "处理完成: 111312\n",
      "处理完成: 103414\n",
      "处理完成: 109123\n",
      "处理完成: 111514\n",
      "处理完成: 107422\n",
      "处理完成: 102816\n",
      "处理完成: 108020\n",
      "处理完成: 104820\n",
      "处理完成: 106824\n",
      "处理完成: 100610\n",
      "处理完成: 102109\n",
      "处理完成: 112920\n",
      "处理完成: 105115\n",
      "处理完成: 108222\n",
      "处理完成: 103111\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#这是每个被试文件夹里有个小文件夹，装的当前被试的切片\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# 基础路径\n",
    "base_dir = \"/mnt/siat205_disk5/munan/HCP_3T_251/\"\n",
    "# 零值占比阈值\n",
    "# zero_ratio_threshold = 0.93\n",
    "\n",
    "subject_dirs = [os.path.join(base_dir, d) for d in os.listdir(base_dir) if os.path.isdir(os.path.join(base_dir, d))]\n",
    "subject_dirs = sorted(subject_dirs)\n",
    "# 遍历所有子文件夹\n",
    "for subject_dir in subject_dirs[210:220]:\n",
    "    subject_id = os.path.basename(subject_dir)  # 提取编号\n",
    "    file_path = os.path.join(subject_dir, \"diffusion_90_directions\", subject_id + \"_90.nii.gz\")\n",
    "    output_dir_subject = os.path.join(subject_dir, \"timehw\")\n",
    "    os.makedirs(output_dir_subject, exist_ok=True)\n",
    "    \n",
    "    if os.path.exists(file_path):\n",
    "        # 加载数组\n",
    "        array, _ = load_nifti(file_path)\n",
    "        array = np.squeeze(array)  # shape [145, 174, 145, 90]\n",
    "        # 转换操作\n",
    "        # 1. 重新排列维度，相当于 permute(2, 3, 1, 0)\n",
    "        transformed_array = np.transpose(array, (2, 3, 1, 0))  # [slice, direction, height, width] (145, 174, 145, 90)\n",
    "        # 2. 翻转第三维，相当于 flip(dims=[2])\n",
    "        transformed_array = np.flip(transformed_array, axis=2)\n",
    "\n",
    "        # 遍历切片\n",
    "        slice_count, direc_count, _, _ = transformed_array.shape\n",
    "        for slice_idx in range(0,slice_count):\n",
    "            # 获取切片\n",
    "            sliced_image = transformed_array[slice_idx, :, :, :]  # shape [height, width]\n",
    "            # 计算零值占比\n",
    "            # zero_ratio = np.sum(sliced_image == 0) / sliced_image.size\n",
    "            # if zero_ratio > zero_ratio_threshold:\n",
    "            #     continue  # 跳过保存\n",
    "\n",
    "            # 保存切片\n",
    "            output_filename = f\"sub{subject_id}_slice{slice_idx:03d}.npy\"\n",
    "            output_path = os.path.join(output_dir_subject, output_filename)\n",
    "            np.save(output_path, sliced_image)\n",
    "\n",
    "        print(f\"处理完成: {subject_id}\")\n",
    "    else:\n",
    "        print(f\"文件不存在: {file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c415f6282f4e13f5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-25T09:27:53.800624Z",
     "start_time": "2024-12-25T09:27:53.782376Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files have been organized into subject folders.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "source_dir = \"/mnt/disk1/munan/subjects/\"\n",
    "files = [os.path.join(source_dir, f) for f in os.listdir(source_dir) if os.path.isdir(os.path.join(source_dir, f))]\n",
    "\n",
    "for file in files:\n",
    "    subject_id = file.split('_')[-1].split('.')[0]\n",
    "    subject_folder = os.path.join(source_dir, subject_id)\n",
    "    if not os.path.exists(subject_folder):\n",
    "        os.makedirs(subject_folder)\n",
    "    shutil.move(os.path.join(source_dir, file), os.path.join(subject_folder, file))\n",
    "    \n",
    "print(\"Files have been organized into subject folders.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "511412f95f65ccad",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-25T07:59:00.265177Z",
     "start_time": "2024-12-25T07:56:13.507822Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100206_3T_Diffusion_preproc\n",
      "100307_3T_Diffusion_preproc\n",
      "100408_3T_Diffusion_preproc\n",
      "100610_3T_Diffusion_preproc\n",
      "101006_3T_Diffusion_preproc\n",
      "101107_3T_Diffusion_preproc\n",
      "101309_3T_Diffusion_preproc\n",
      "101410_3T_Diffusion_preproc\n",
      "101915_3T_Diffusion_preproc\n",
      "102008_3T_Diffusion_preproc\n",
      "(145, 174, 145, 191)\n",
      "102008_3T_Diffusion_preproc\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "exceptions must derive from BaseException",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[3], line 20\u001B[0m\n\u001B[1;32m     18\u001B[0m     \u001B[38;5;28mprint\u001B[39m(data\u001B[38;5;241m.\u001B[39mshape)\n\u001B[1;32m     19\u001B[0m     \u001B[38;5;28mprint\u001B[39m(file_str)\n\u001B[0;32m---> 20\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdwi original data\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124ms shape is not right\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m     21\u001B[0m \u001B[38;5;66;03m#---------------------------------------获得各个shell的索引-----------------------------------------\u001B[39;00m\n\u001B[1;32m     22\u001B[0m \u001B[38;5;66;03m# 18个b0,其余每个b值各90  \u001B[39;00m\n\u001B[1;32m     23\u001B[0m b0 \u001B[38;5;241m=\u001B[39m []\n",
      "\u001B[0;31mTypeError\u001B[0m: exceptions must derive from BaseException"
     ]
    }
   ],
   "source": [
    "root = '/mnt/disk4/hcp_fa_ad/hcp-78/'\n",
    "save_path = '/mnt/disk1/munan/dwi/'\n",
    "files = sorted(os.listdir(root))\n",
    "dwi_90_allsubs = []\n",
    "for file in files[:9]:\n",
    "    print(file)\n",
    "    file_str = str(file)\n",
    "    file_name = file_str.split(\"_\")[0]\n",
    "    data_path = root + file + '/' + file_name + '/T1w/Diffusion/data.nii.gz'\n",
    "    bval_path = root + file + '/' + file_name + '/T1w/Diffusion/bvals'\n",
    "    bvec_path = root + file + '/' + file_name + '/T1w/Diffusion/bvecs'\n",
    "    mask_path = root + file + '/' + file_name + '/T1w/Diffusion/nodif_brain_mask.nii.gz'\n",
    "\n",
    "    data, affine = load_nifti(data_path)\n",
    "    # bvals = 0, 1000, 2000, 3000; bvecs.shape (288, 3)\n",
    "    bvals, bvecs = read_bvals_bvecs(bval_path, bvec_path)\n",
    "    if data.shape[-1] != 288:\n",
    "        print(data.shape)\n",
    "        print(file_str)\n",
    "        raise \"dwi original data's shape is not right\"\n",
    "    #---------------------------------------获得各个shell的索引-----------------------------------------\n",
    "    # 18个b0,其余每个b值各90  \n",
    "    b0 = []\n",
    "    b1 = []\n",
    "    b2 = []\n",
    "    b3 = []\n",
    "    i = 0\n",
    "    for i in range(288):\n",
    "        b = bvals[i]\n",
    "        if abs(b - 0) == min(abs(b - 0), abs(b - 1000), abs(b - 2000), abs(b - 3000)):\n",
    "            b0.append(i)\n",
    "            # print(\"b0:new index\",i)\n",
    "        elif abs(b - 1000) == min(abs(b - 0), abs(b - 1000), abs(b - 2000), abs(b - 3000)):\n",
    "            b1.append(i)\n",
    "            # print(\"b1:new index\",i)\n",
    "        elif abs(b - 2000) == min(abs(b - 0), abs(b - 1000), abs(b - 2000), abs(b - 3000)):\n",
    "            b2.append(i)\n",
    "        else:\n",
    "            b3.append(i)\n",
    "     #---------------------------------------------------------------------------------------------\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e46e147a8d026061",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-26T03:19:38.734782Z",
     "start_time": "2024-08-26T03:19:38.089926Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT mask shape:\t (145, 174, 145)\n",
      "b0 average\n",
      "\n",
      "b1_data_shape:\t (145, 174, 145, 90) \n",
      "b0_shape:\t (145, 174, 145, 1)\n"
     ]
    }
   ],
   "source": [
    "#这是一整个大文件夹里装的所有被试的切片\n",
    "path = \"/mnt/disk5/munan/HCP_3T_251/100206/diffusion_90_directions/100206_brain_mask.nii.gz\"\n",
    "# 基础路径\n",
    "base_dir = \"/mnt/disk5/munan/HCP_3T_251/\"\n",
    "output_dir = \"/mnt/disk5/munan/sliced_data_251\"  # 结果保存路径\n",
    "os.listdir(base_dir)\n",
    "os.makedirs(output_dir, exist_ok=True)  # 创建输出路径\n",
    "\n",
    "# 零值占比阈值\n",
    "zero_ratio_threshold = 0.93\n",
    "\n",
    "subject_dirs = [os.path.join(base_dir, d) for d in os.listdir(base_dir) if os.path.isdir(os.path.join(base_dir, d))]\n",
    "\n",
    "# 遍历所有子文件夹\n",
    "for subject_dir in subject_dirs:\n",
    "    subject_id = os.path.basename(subject_dir)  # 提取编号\n",
    "    file_path = os.path.join(subject_dir,\"diffusion_90_directions\", subject_id + \"_90.nii.gz\")\n",
    "    output_dir_subject = os.path.join(output_dir, subject_id)\n",
    "    os.makedirs(output_dir_subject, exist_ok=True)\n",
    "    \n",
    "    if os.path.exists(file_path):\n",
    "        # 加载nii,to numpy数组\n",
    "        array, affine = load_nifti(file_path)\n",
    "        array = np.squeeze(array)  # shape [145, 174, 145, 90]\n",
    "        # 转换操作\n",
    "        # 1. 重新排列维度，相当于 permute(2, 3, 1, 0)\n",
    "        transformed_array = np.transpose(array, (2, 3, 1, 0))  # [slice, direction, height, width]\n",
    "        # 2. 翻转第三维，相当于 flip(dims=[2])\n",
    "        transformed_array = np.flip(transformed_array, axis=2)\n",
    "        \n",
    "        # 遍历切片\n",
    "        slice_count, direc_count, _, _ = transformed_array.shape\n",
    "        for slice_idx in range(10, slice_count - 10):\n",
    "            # Check zero ratio across all directions for the current slice\n",
    "            zero_ratios = [\n",
    "                np.sum(transformed_array[slice_idx, direc_idx, :, :] == 0) /\n",
    "                transformed_array[slice_idx, direc_idx, :, :].size\n",
    "                for direc_idx in range(direc_count)\n",
    "            ]\n",
    "            \n",
    "            # If any direction in the slice exceeds the zero ratio threshold, skip the entire slice\n",
    "            if any(zero_ratio > zero_ratio_threshold for zero_ratio in zero_ratios):\n",
    "                continue\n",
    "            \n",
    "            # Save all directions for the current slice\n",
    "            for direc_idx in range(direc_count):\n",
    "                sliced_image = transformed_array[slice_idx, direc_idx, :, :]  # shape [height, width]\n",
    "                output_filename = f\"sub{subject_id}_slice{slice_idx:03d}_direc{direc_idx:03d}.npy\"\n",
    "                output_path = os.path.join(output_dir_subject, output_filename)\n",
    "                np.save(output_path, sliced_image)\n",
    "        \n",
    "        print(f\"处理完成: {subject_id}\")\n",
    "    else:\n",
    "        print(f\"文件不存在: {file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c11c1f0dba3ed2ca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-26T03:19:44.921771Z",
     "start_time": "2024-08-26T03:19:41.465438Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 90/90 [00:03<00:00, 26.13it/s]\n"
     ]
    }
   ],
   "source": [
    "dwi_90_allsubs = []\n",
    "progress_bar = tqdm(range(b1_data.shape[-1]))\n",
    "for i in progress_bar:\n",
    "    data_gt = b1_data[...,i:i+1] / (b0+1e-5)#除b0正则化\n",
    "\n",
    "    data_gt = np.nan_to_num(data_gt, copy=True, nan=0, posinf=0, neginf=0)\n",
    "    data_gt = np.clip(data_gt, 0, 1)\n",
    "    data_gt = data_gt * np.expand_dims(GT_mask, axis=-1)\n",
    "\n",
    "    dwi_90_allsubs.append(data_gt)\n",
    "# data_gt_masked = np.concatenate(dwi_90_allsubs, axis=-1)\n",
    "    # print(\"newly added sub'shape is: \\t\",dwi_90_allsubs[i].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e09a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "##------------generate /munan/subjects,每一个sub的90方向volume生成-------##\n",
    "root = '/mnt/disk4/hcp_fa_ad/hcp-78/'\n",
    "save_path = '/mnt/disk1/munan/subjects/'\n",
    "files = sorted(os.listdir(root))\n",
    "files.pop(9)\n",
    "os.makedirs(save_path, exist_ok=True)\n",
    "index_1 = [7, 37, 39, 68, 69, 81]\n",
    "index_2 = [1, 4, 25, 30, 72, 76]\n",
    "index_3 = [26, 45, 58, 71, 73, 80]\n",
    "prog_bar = tqdm(enumerate(files[:]))\n",
    "for i, file in prog_bar:\n",
    "\n",
    "    file_str = str(file)\n",
    "    file_name = file_str.split(\"_\")[0]\n",
    "    print(i,file,file_name)\n",
    "    # os.makedirs((osp.join(save_path,file_name)), exist_ok=True)\n",
    "    # data_path = root  + file_name + '/dmri.nii.gz'\n",
    "    bval_path = root + file + '/'+ file_name + '/T1w/Diffusion/bvals'\n",
    "    bvec_path = root + file + '/'+ file_name + '/T1w/Diffusion/bvecs'\n",
    "    # fa_path = root + file + '/' + file_name + '/T1w/Diffusion/fa.nii.gz'\n",
    "    # ad_path = root + file + '/' + file_name + '/T1w/Diffusion/ad.nii.gz'\n",
    "    # md_path = root + file + '/' + file_name + '/T1w/Diffusion/md.nii.gz'\n",
    "    # od_path = noddi_path + file_name + '/FIT_OD.nii.gz'\n",
    "    # ic_path = noddi_path + file_name + '/FIT_ICVF.nii.gz'\n",
    "    # iso_path = noddi_path + file_name + '/FIT_ISOVF.nii.gz'\n",
    "    mask_path = root + file + '/'+ file_name + '/T1w/Diffusion/nodif_brain_mask.nii.gz'\n",
    "    # data.shape (145, 174, 145, 288)\n",
    "    # data, affine = load_nifti(data_path)\n",
    "    mask,_ = load_nifti(mask_path)\n",
    "    np.save(os.path.join(save_path,f'brain_mask_{file_name}.npy'),mask)\n",
    "    # mask_new = nib.Nifti1Image(mask, np.eye(4))\n",
    "    # nib.save(mask_new,osp.join(save_path,file_name,f'brain_mask_{file_name}.nii.gz'))\n",
    "    print(\"mask saved\")\n",
    "    # bvals = 0, 1000, 2000, 3000; bvecs.shape (288, 3)\n",
    "    bvals, bvecs = read_bvals_bvecs(bval_path, bvec_path)\n",
    "    # if data.shape[-1] != 288:\n",
    "    #     raise \"dwi original data's shape is not right\"\n",
    "    b0 = []\n",
    "    b1 = []\n",
    "    b2 = []\n",
    "    b3 = []\n",
    "    i = 0\n",
    "    for i in range(288):\n",
    "        b = bvals[i]\n",
    "        if abs(b - 0) == min(abs(b - 0), abs(b - 1000), abs(b - 2000), abs(b - 3000)):\n",
    "            b0.append(i)\n",
    "        elif abs(b - 1000) == min(abs(b - 0), abs(b - 1000), abs(b - 2000), abs(b - 3000)):\n",
    "            b1.append(i)\n",
    "        elif abs(b - 2000) == min(abs(b - 0), abs(b - 1000), abs(b - 2000), abs(b - 3000)):\n",
    "            b2.append(i)\n",
    "        else:\n",
    "            b3.append(i)\n",
    "    # b1_data = data[:, :, :, b1]\n",
    "    b1_bvals = bvals[b1] \n",
    "    b1_bvecs = bvecs[b1, :]\n",
    "    # print(b1_data.shape)\n",
    "    # new_image = nib.Nifti1Image(b1_data, np.eye(4)) \n",
    "    # nib.save(new_image, osp.join(save_path,file_name,f'{file_name}_90.nii.gz'))\n",
    "    np.savetxt(osp.join(save_path,f'bvecs_90_{file_name}.txt'), b1_bvecs, delimiter=' ')\n",
    "    # np.savetxt(osp.join(save_path,f'bvals_90_{file_name}.txt'), b1_bvals, delimiter=' ')\n",
    "\n",
    "    # b1_data_selected = b1_data[:, :, :, index_1]\n",
    "    # b1_bvals_selected = b1_bvals[index_1]\n",
    "    # b1_bvecs_selected = b1_bvecs[index_1, :]\n",
    "    # print(b1_data_selected.shape)\n",
    "    # new_image_6 = nib.Nifti1Image(b1_data_selected, np.eye(4)) \n",
    "    # nib.save(new_image_6, osp.join(save_path,file_name,f'{file_name}_06.nii.gz'))\n",
    "    # np.savetxt(osp.join(save_path,file_name,f'{file_name}_bvecs_06.txt'), b1_bvecs_selected, delimiter=' ')\n",
    "    # np.savetxt(osp.join(save_path,file_name,f'{file_name}_bvals_06.txt'), b1_bvals_selected, delimiter=' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2990e650f76ebe0",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8bec9104c29d1053",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LDM",
   "language": "python",
   "name": "ldm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
