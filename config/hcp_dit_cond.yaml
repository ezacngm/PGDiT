dataset_params:
  data_folder: '/mnt/siat205_disk5/munan/HCP_3T_251/'
  im_channels : 1
  im_size : 63
  name: 'HCP'
  normalise: False
  q_space_directions: 90
  shell: 1
  kth_subject: 90

diffusion_params:
  num_timesteps : 1000
  beta_start : 0.0015
  beta_end : 0.0195

dit_params:
  model: "VDT-L/4"
  num_timesteps : 1000
  num_classes: 1
  cfg_scale: 4.0
  num_sampling_respace: 50
  num_frames: 90
  bvec_emb: "mlp"
  finetune_ckpt: 
  learn_sigma: True
  sigma_small: False
  predict_xstart: False


ldm_params:
  down_channels: [ 256, 384, 512, 768 ]
  mid_channels: [ 768, 512 ]
  down_sample: [ True, True, True ]
  attn_down : [True, True, True]
  time_emb_dim: 512
  norm_channels: 32
  num_heads: 16
  conv_out_channels : 128
  num_down_layers : 2
  num_mid_layers : 2
  num_up_layers : 2

autoencoder_params:
  z_channels: 4
  codebook_size : 16384
  down_channels : [128, 256, 512]
  mid_channels : [512, 512]
  down_sample : [True, True]
  attn_down : [False, False]
  norm_channels: 32
  num_heads: 4
  num_down_layers : 2
  num_mid_layers : 2
  num_up_layers : 2


train_params:
  seed : 1111
  wandb_on: True
  vae_name: 
  dit_name: 
  ldm_batch_size: 1
  autoencoder_batch_size: 30
  disc_start: 0
  disc_weight: 0.5
  codebook_weight: 1.5
  commitment_beta: 0.2
  perceptual_weight: 0.5
  kl_weight: 0.000005
  ldm_epochs: 1000
  autoencoder_epochs: 1000
  num_samples: 50
  num_grid_rows: 25
  ldm_lr: 0.000002
  dit_lr:
  autoencoder_lr: 0.00001
  autoencoder_acc_steps: 1
  autoencoder_img_save_steps: 64
  model_save_steps: 5000
  save_latents : False
  vae_latent_dir_name: 'vae_latents'
  vqvae_latent_dir_name: 'vqvae_latents'
  ldm_ckpt_name: 'ddpm_cond_ckpt.pth'
  dit_ckpt_name: 'dit_cond_ckpt.pth'
  vqvae_autoencoder_ckpt_name: 'vqvae_autoencoder_ckpt.pth'
  vae_autoencoder_ckpt_name: 'vae_autoencoder_ckpt.pth'
  vqvae_discriminator_ckpt_name: 'vqvae_discriminator_ckpt.pth'
  vae_discriminator_ckpt_name: 'vae_discriminator_ckpt.pth'
